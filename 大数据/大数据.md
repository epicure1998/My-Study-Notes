

[TOC]

# 大数据

## Zookeeper

解决分布式系统，在资源调用上的一致性问题和数据管理问题。

分布式系统协调框架，避免资源调用混乱。调配网络中的分布式资源。

分布式锁和普通进程锁有区别：

![image-20201014112040206](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201014112040206.png)

### Zookeeper的特点

* 保证数据的一致性
* 是一个集群，可以分布在多个主机上
* 集群化的Zookeeper会对外提供一个树形结构的访问路径。将整个集群整合后对外暴露一个目录
* Zookeeper中存储的其实是一个又一个的Znode，是Zookeeper中的节点
* Znode有路径，/data/host1，/data/host2
* Znode也可以携带数据

### Zookeeper的架构

![image-20201014125553503](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201014125553503.png)

* Leader：
   * 老大，核心
   * 管理整个集群的调度
   * 处理事务型的请求（写操作）
   * 参与投票
* Follower：
   * 接收客户端的请求
   * 处理非事务请求（读）
   * 转发事务给Leader
   * 参与集群投票
* Observer（可选）
   * 向集群发起请求

### Zookeeper的应用场景

#### 数据的发布订阅

推模式，拉模式

实时的获取最新的元数据

![image-20201014130959548](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201014130959548.png)

#### 命名服务

类比Linux的文件系统。将集群整合后暴露一个统一唯一的路径

#### 分布式协调通知

> 心跳检测:用于检测集群中的主机是否存活

> 工作进度汇报：

> 系统调度：

### 分布式锁：

* 排他锁
* 共享锁
* 分布式队列

### Zookeeper的选举机制

* myid:权值
* ZXID:数据新旧
* 服务器的个数最好是基数个

> 集群启动时开始投票：
>
> 得票的服务器数量过半后开始统计票数，ZXID大的直接当选。如果ZXID相同，比较myid大 的当选。然后更新服务器的状态

### 集群搭建：

### Zookeeper的数据模型：

文件树，树形层次结构，类比Linux的XFS学习。

* Znode兼具文件和目录的两种特点
* Znode存数据大小有限制：存储状态信息，配置信息
* Znode通过路径引用：必须是绝对路径
* 每个Znode分为三个部分：

### Znode节点类型：

零时节点：生命周期依赖于Session。零时节点不能有子节点。可用来判断主机是否宕机

> 

永久节点：永久存活，只有删除操作才删除:

>PERSISTENT:
>
>PERSISTENT_SEQUENTIAL:

序列化特性

### 命令操作：

```bash
create -s -e path data acl
#-s 顺序节点
#-e 零时节点
#data 数据
```







## Hadoop

* 提供接口，屏蔽底层细节。高可用，可扩展性
* Java
* 一系列大数据处理工具的集合体
* Doug Cutting
* 源起google，GFS,MapReduce
* 成本低，普通PC也可以一个集群
* 最典型的三种应用：
   * 数据分析
   * 数据实时查询
   * 数据挖掘
   * ![image-20201014103504809](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201014103504809.png)

>Hadoop版本的选择：
>
>* 是否开源
>* 是否有稳定版
>* 是否有别人使用的经历
>* 是否提供社区服务

### 项目结构

![image-20201014104413165](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201014104413165.png)

* HDFS:负责文件的分布式存储
* YARN:底层资源的调度
* MapReduce:离线的批处理
* Spark:基于内存计算，MR是基于磁盘的，Spark更快
* Hive:数据仓库，支持SQL语句，易于兼容，HIVE会将类SQL语句转换成为一系列的MapReduce来处理数据
* Pig:流数据处理，轻量级，类比Hive，也支持类SQL语句。嵌套执行。比MR更加简单。轻量级脚本语言
* Oozie:工作流管理工具
* ZooKeeper：管家，集群管理，分布式锁
* Hbase：非关系型数据库
* Flume：日志
* Sqoop：关系型数据库与Hadoop平台之间==互导==数据
* Ambari：部署工具，支持Apache Hadoop 集群的供应，管理和监控

## HDFS

数据存储

## Hbase

* 非关系型数据库

* 面向列的存储，传统的数据库是通过行存储：

   * >行式优缺点：
      >
      >为了行式存储来讲，为了取出年龄这一行数据，必须先去扫描数据库的第一行，然后这行的年龄字段取出来，再去扫描第二行，分析效率低下。但是适合==事务型操作==。
      >
      >列式存储优缺点：按照列去存储，提高数据压缩率，分析数据效率高。
      >
      >

* 对数据的定位：四维度。行键，列族，列限定符，时间戳

* 稀疏表，每个单元格可以为空

### Hbase功能组件

* Region会不停的分裂

* Region的寻址和定位，三层架构

   * > ZooKeeper->Root->META->用户数据表

* 客户端会将寻址信息缓存下来：惰性解决，当发现数据更新，无法返回正确的数据时，重新建立缓存
* 每个Region服务器可以存储10-1000具体用户的数据region，一个服务器一个HLog日志文件

### 写入数据

 首先写入缓存中，然后写入HLOG中记录日志

![image-20201013154601258](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013154601258.png)

### 读取数据

先访问在缓存MemStore中找数据，因为数据被写入首先被存入了缓存，找不到再从磁盘查找。![image-20201013154739087](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013154739087.png)

### 缓存的刷新

周期性地把MemStore缓存里的内容刷入磁盘![image-20201013160924805](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013160924805.png)

 StoreFile会逐渐合并。 达到阈值又会触发分裂。

## HBase应用方案

### 读写性能的提升

* 性能的检测：
   * Master-status
   * Ganglia
   * Ambari

### 引擎：

* HIVE
* Phoenix

### Hbase 应用方案

Hbase 不支持多级索引，各个列构建相关的索引默认只支持对rowkey行键进行索引

利用enterpoint,observer构建二级索引，缺点是每插入一条数据需要向索引表插入数据，耗时两倍，对HBase的集群的压力时双倍的

Hindex

HBase+Index

## MapReduce

海量数据的处理

Map阶段负责分，Reduce阶段负责合。将一个大型的整体数据先拆分，分片处理后再将处理的结果合并分析。

![image-20201013171050322](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013171050322.png)

### 设计构思：

MapTask: 分

ReduceTask:合

MapReduce提供了Map和Reduce的接口，通过实现接口对数据进行处理

![image-20201013172716056](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013172716056.png)

### 编程规范

#### Map阶段 2步

1. 设置InputFormat类（一般使用它的子类，TextInputFormat），将数据切分的K-V，输入到第二步。

2. 自定义Map逻辑，将第一步的结果转换为K2-V2。要重写一个方法，继承自Mapper

   ```java
    public class WordCountMapper extends Mapper<LongWritable,Text,Text,LongWritable>{
      @Override
      protected void map()...
    }
   //为什么不用java本身提供的数据类型呢？
   //在p级的数据条件时，long数据类型一方面会不足够使用，2^64 次方，并且在将数据序列号时传统的数据类型会显得笨重
   ```

   ![image-20201013232849124](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013232849124.png)

   ![image-20201013174545933](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013174545933.png)

#### Shuffle阶段 4步

3. 对输出的k-v对进行==分区==
4. 对不同分区的数据按照相同的key==排序==
5. ==规约==？将重复数据简化，交集合并？？
6. ==分组==，将k-v放入一个集合，数据过滤，去重复？

#### Reduce

7. 再次处理键值对，继承Reducer类
8. 输出OutputFormat

![image-20201013180159066](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013180159066.png)

***

案例演示：  每次的map数据转换其实可以理解成为处理了ma p数据后将数据再封装成一个map数据进行向后传递

Shaffle如果不对其进行自定义，重写其方法，就会进行键值对合并 