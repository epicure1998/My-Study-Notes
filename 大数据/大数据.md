

[TOC]

# 大数据

## HDFS



## Hbase

* 非关系型数据库

* 面向列的存储，传统的数据库是通过行存储：

   * >行式优缺点：
      >
      >为了行式存储来讲，为了取出年龄这一行数据，必须先去扫描数据库的第一行，然后这行的年龄字段取出来，再去扫描第二行，分析效率低下。但是适合==事务型操作==。
      >
      >列式存储优缺点：按照列去存储，提高数据压缩率，分析数据效率高。
      >
      >

* 对数据的定位：四维度。行键，列族，列限定符，时间戳

* 稀疏表，每个单元格可以为空

### Hbase功能组件

* Region会不停的分裂

* Region的寻址和定位，三层架构

   * > ZooKeeper->Root->META->用户数据表

* 客户端会将寻址信息缓存下来：惰性解决，当发现数据更新，无法返回正确的数据时，重新建立缓存
* 每个Region服务器可以存储10-1000具体用户的数据region，一个服务器一个HLog日志文件

### 写入数据

 首先写入缓存中，然后写入HLOG中记录日志

![image-20201013154601258](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013154601258.png)

### 读取数据

先访问在缓存MemStore中找数据，因为数据被写入首先被存入了缓存，找不到再从磁盘查找。![image-20201013154739087](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013154739087.png)

### 缓存的刷新

周期性地把MemStore缓存里的内容刷入磁盘![image-20201013160924805](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013160924805.png)

 StoreFile会逐渐合并。 达到阈值又会触发分裂。

## HBase应用方案

### 读写性能的提升

* 性能的检测：
   * Master-status
   * Ganglia
   * Ambari

### 引擎：

* HIVE
* Phoenix

### Hbase 应用方案

Hbase 不支持多级索引，各个列构建相关的索引默认只支持对rowkey行键进行索引

利用enterpoint,observer构建二级索引，缺点是每插入一条数据需要向索引表插入数据，耗时两倍，对HBase的集群的压力时双倍的

Hindex

HBase+Index

## MapReduce

Map阶段负责分，Reduce阶段负责合。将一个大型的整体数据先拆分，分片处理后再将处理的结果合并分析。

![image-20201013171050322](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013171050322.png)

### 设计构思：

MapTask: 分

ReduceTask:合

MapReduce提供了Map和Reduce的接口，通过实现接口对数据进行处理

![image-20201013172716056](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013172716056.png)

### 编程规范

#### Map阶段 2步

1. 设置InputFormat类（一般使用它的子类，TextInputFormat），将数据切分的K-V，输入到第二步。

2. 自定义Map逻辑，将第一步的结果转换为K2-V2。要重写一个方法，继承自Mapper

   ```java
    public class WordCountMapper extends Mapper<LongWritable,Text,Text,LongWritable>{
      @Override
      protected void map()...
    }
   //为什么不用java本身提供的数据类型呢？
   //在p级的数据条件时，long数据类型一方面会不足够使用，2^64 次方，并且在将数据序列号时传统的数据类型会显得笨重
   ```

   ![image-20201013232849124](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013232849124.png)

   ![image-20201013174545933](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013174545933.png)

#### Shuffle阶段 4步

3. 对输出的k-v对进行==分区==
4. 对不同分区的数据按照相同的key==排序==
5. ==规约==？将重复数据简化，交集合并？？
6. ==分组==，将k-v放入一个集合，数据过滤，去重复？

#### Reduce

7. 再次处理键值对，继承Reducer类
8. 输出OutputFormat

![image-20201013180159066](/Users/apple/Desktop/My-Study-Notes/大数据/image-20201013180159066.png)

***

案例演示：  每次的map数据转换其实可以理解成为处理了ma p数据后将数据再封装成一个map数据进行向后传递

Shaffle如果不对其进行自定义，重写其方法，就会进行键值对合并 